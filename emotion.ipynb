{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "66e2d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c048786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "614c018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATH SETUP ===\n",
    "ravdess_path = r\"C:\\Users\\abdul\\Downloads\\audio-testing\\RAVDESS-AUDIO-DATASET\"\n",
    "crema_path = r\"C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\"\n",
    "tess_path = r\"C:\\Users\\abdul\\Downloads\\audio-testing\\TESS Toronto emotional speech set data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c60321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Label extractors for each dataset ===\n",
    "def extract_label_ravdess(file):\n",
    "    parts = os.path.basename(file).split(\"-\")\n",
    "    emotion_code = parts[2]\n",
    "    return {\n",
    "        '01': 'neutral',\n",
    "        '02': 'calm',\n",
    "        '03': 'happy',\n",
    "        '04': 'sad',\n",
    "        '05': 'angry',\n",
    "        '06': 'fearful',\n",
    "        '07': 'disgust',\n",
    "        '08': 'surprised'\n",
    "    }.get(emotion_code, \"unknown\")\n",
    "\n",
    "def extract_label_crema(file):\n",
    "    parts = os.path.basename(file).split('_')\n",
    "    return {\n",
    "        'ANG': 'angry',\n",
    "        'DIS': 'disgust',\n",
    "        'FEA': 'fearful',\n",
    "        'HAP': 'happy',\n",
    "        'NEU': 'neutral',\n",
    "        'SAD': 'sad'\n",
    "    }.get(parts[2], \"unknown\")\n",
    "\n",
    "def extract_label_tess(file):\n",
    "    name = os.path.basename(file)\n",
    "    return name.split('_')[-1].replace('.wav', '').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0f591125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# 1. Add White Noise\n",
    "def add_noise(y, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(y))\n",
    "    return y + noise_factor * noise\n",
    "\n",
    "# 2. Shift Audio (Time Shift)\n",
    "def shift_audio(y, shift_max=0.2):\n",
    "    shift = int(random.uniform(-shift_max, shift_max) * len(y))\n",
    "    return np.roll(y, shift)\n",
    "\n",
    "# 3. Time Stretching\n",
    "def stretch_audio(y, rate=1.1):\n",
    "    try:\n",
    "        return librosa.effects.time_stretch(y, rate)\n",
    "    except Exception as e:\n",
    "        print(f\"Stretch error: {e}\")\n",
    "        return y\n",
    "\n",
    "# 4. Pitch Shifting\n",
    "def pitch_shift_audio(y, sr, n_steps=2):\n",
    "    try:\n",
    "        return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "    except Exception as e:\n",
    "        print(f\"Pitch shift error: {e}\")\n",
    "        return y\n",
    "\n",
    "# 5. Dynamic Range Compression\n",
    "def dynamic_range_compression(y, C=1, clip_val=0.05):\n",
    "    return np.tanh(C * y) / clip_val\n",
    "\n",
    "# 6. Volume Change (Random Gain)\n",
    "def random_volume_change(y, low=0.8, high=1.2):\n",
    "    return y * random.uniform(low, high)\n",
    "\n",
    "# 7. Add Background Noise (Requires loading external background sound)\n",
    "def add_background_noise(y, bg, snr_db=10):\n",
    "    rms_y = np.sqrt(np.mean(y**2))\n",
    "    rms_bg = np.sqrt(np.mean(bg**2))\n",
    "    bg = bg[:len(y)] if len(bg) > len(y) else np.pad(bg, (0, len(y) - len(bg)), 'wrap')\n",
    "    bg = bg * (rms_y / (10**(snr_db / 20)) / rms_bg)\n",
    "    return y + bg\n",
    "\n",
    "# 8. Bandpass Filter (Simulate mic/environment frequency limitations)\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    return butter(order, [low, high], btype='band')\n",
    "\n",
    "def apply_bandpass_filter(y, sr, lowcut=300.0, highcut=3000.0):\n",
    "    b, a = butter_bandpass(lowcut, highcut, sr, order=4)\n",
    "    return lfilter(b, a, y)\n",
    "\n",
    "# 9. Add Echo\n",
    "def add_echo(y, sr, delay=0.2, decay=0.5):\n",
    "    delay_samples = int(delay * sr)\n",
    "    echo = np.zeros_like(y)\n",
    "    echo[delay_samples:] = y[:-delay_samples]\n",
    "    return y + decay * echo\n",
    "\n",
    "# 10. Insert Random Silence\n",
    "def insert_silence(y, sr, max_silence_sec=0.3):\n",
    "    silence_duration = int(sr * random.uniform(0.1, max_silence_sec))\n",
    "    silence = np.zeros(silence_duration)\n",
    "    insert_point = random.randint(0, len(y) - silence_duration)\n",
    "    return np.concatenate([y[:insert_point], silence, y[insert_point:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2a86c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, label_extractor, augment=False):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(file, sr=22050, mono=True)\n",
    "\n",
    "        # Apply random augmentation if enabled\n",
    "        if augment:\n",
    "            aug_type = random.choice([\n",
    "                'noise', 'shift', 'stretch', 'pitch', 'compression',\n",
    "                'volume', 'echo', 'silence', 'bandpass'\n",
    "            ])\n",
    "            if aug_type == 'noise':\n",
    "                y = add_noise(y)\n",
    "            elif aug_type == 'shift':\n",
    "                y = shift_audio(y)\n",
    "            elif aug_type == 'stretch':\n",
    "                y = stretch_audio(y, rate=random.uniform(0.8, 1.2))\n",
    "            elif aug_type == 'pitch':\n",
    "                y = pitch_shift_audio(y, sr=sr, n_steps=random.randint(-2, 2))\n",
    "            elif aug_type == 'compression':\n",
    "                y = dynamic_range_compression(y)\n",
    "            elif aug_type == 'volume':\n",
    "                y = random_volume_change(y)\n",
    "            elif aug_type == 'echo':\n",
    "                y = add_echo(y, sr)\n",
    "            elif aug_type == 'silence':\n",
    "                y = insert_silence(y, sr)\n",
    "            elif aug_type == 'bandpass':\n",
    "                y = apply_bandpass_filter(y, sr)\n",
    "\n",
    "        features = []\n",
    "\n",
    "        # MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        features.extend(np.mean(mfccs, axis=1))\n",
    "        features.extend(np.std(mfccs, axis=1))\n",
    "\n",
    "        # Chroma\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        features.extend(np.mean(chroma, axis=1))\n",
    "        features.extend(np.std(chroma, axis=1))\n",
    "\n",
    "        # Zero Crossing Rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        features.append(np.mean(zcr))\n",
    "        features.append(np.std(zcr))\n",
    "\n",
    "        # Root Mean Square Energy\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        features.append(np.mean(rms))\n",
    "        features.append(np.std(rms))\n",
    "\n",
    "        # Spectral Contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        features.extend(np.mean(contrast, axis=1))\n",
    "        features.extend(np.std(contrast, axis=1))\n",
    "\n",
    "        # Label\n",
    "        label = label_extractor(file)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4f162a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load and Extract Features from All Datasets ===\n",
    "data = []\n",
    "\n",
    "# RAVDESS\n",
    "for file in glob(os.path.join(ravdess_path, '**', '*.wav'), recursive=True):\n",
    "    f, l = extract_features(file, extract_label_ravdess)\n",
    "    if f and l != \"unknown\":\n",
    "        data.append((f, l))\n",
    "\n",
    "# CREMA-D\n",
    "for file in glob(os.path.join(crema_path, '*.wav')):\n",
    "    f, l = extract_features(file, extract_label_crema)\n",
    "    if f and l != \"unknown\":\n",
    "        data.append((f, l))\n",
    "\n",
    "# TESS\n",
    "for file in glob(os.path.join(tess_path, '**', '*.wav')):\n",
    "    f, l = extract_features(file, extract_label_tess)\n",
    "    if f and l != \"unknown\":\n",
    "        data.append((f, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7ea4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create DataFrame ===\n",
    "features, labels = zip(*data)\n",
    "df = pd.DataFrame(features)\n",
    "df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-697.792603</td>\n",
       "      <td>54.890041</td>\n",
       "      <td>0.663465</td>\n",
       "      <td>12.435786</td>\n",
       "      <td>7.733952</td>\n",
       "      <td>0.530750</td>\n",
       "      <td>-3.216631</td>\n",
       "      <td>-3.159394</td>\n",
       "      <td>-10.977551</td>\n",
       "      <td>-2.848711</td>\n",
       "      <td>...</td>\n",
       "      <td>16.763104</td>\n",
       "      <td>45.346246</td>\n",
       "      <td>10.712655</td>\n",
       "      <td>4.592027</td>\n",
       "      <td>5.519944</td>\n",
       "      <td>3.719688</td>\n",
       "      <td>3.160476</td>\n",
       "      <td>4.936189</td>\n",
       "      <td>4.376869</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-692.855774</td>\n",
       "      <td>55.363895</td>\n",
       "      <td>-1.548319</td>\n",
       "      <td>16.038305</td>\n",
       "      <td>8.818810</td>\n",
       "      <td>-0.146586</td>\n",
       "      <td>-1.373392</td>\n",
       "      <td>-5.293180</td>\n",
       "      <td>-11.623182</td>\n",
       "      <td>-1.348284</td>\n",
       "      <td>...</td>\n",
       "      <td>16.843068</td>\n",
       "      <td>44.918227</td>\n",
       "      <td>10.221810</td>\n",
       "      <td>4.672584</td>\n",
       "      <td>5.678050</td>\n",
       "      <td>4.050266</td>\n",
       "      <td>3.132121</td>\n",
       "      <td>4.980014</td>\n",
       "      <td>4.449650</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-691.587891</td>\n",
       "      <td>58.024662</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>13.624650</td>\n",
       "      <td>5.374113</td>\n",
       "      <td>1.162337</td>\n",
       "      <td>-2.083360</td>\n",
       "      <td>-5.382585</td>\n",
       "      <td>-10.332824</td>\n",
       "      <td>-3.662081</td>\n",
       "      <td>...</td>\n",
       "      <td>16.694574</td>\n",
       "      <td>45.031481</td>\n",
       "      <td>10.610992</td>\n",
       "      <td>5.361405</td>\n",
       "      <td>6.009305</td>\n",
       "      <td>3.831685</td>\n",
       "      <td>2.924071</td>\n",
       "      <td>4.630189</td>\n",
       "      <td>4.303702</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-685.105469</td>\n",
       "      <td>55.879421</td>\n",
       "      <td>2.783262</td>\n",
       "      <td>13.252023</td>\n",
       "      <td>6.989670</td>\n",
       "      <td>2.981274</td>\n",
       "      <td>-1.586029</td>\n",
       "      <td>-6.961661</td>\n",
       "      <td>-10.348489</td>\n",
       "      <td>-3.270769</td>\n",
       "      <td>...</td>\n",
       "      <td>16.067050</td>\n",
       "      <td>44.119110</td>\n",
       "      <td>9.945630</td>\n",
       "      <td>4.248116</td>\n",
       "      <td>4.827358</td>\n",
       "      <td>3.778959</td>\n",
       "      <td>2.933074</td>\n",
       "      <td>3.786002</td>\n",
       "      <td>4.105325</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-727.104370</td>\n",
       "      <td>62.355034</td>\n",
       "      <td>3.121181</td>\n",
       "      <td>15.064669</td>\n",
       "      <td>8.132434</td>\n",
       "      <td>1.927084</td>\n",
       "      <td>-3.274656</td>\n",
       "      <td>-3.761792</td>\n",
       "      <td>-9.750299</td>\n",
       "      <td>-4.853837</td>\n",
       "      <td>...</td>\n",
       "      <td>16.215825</td>\n",
       "      <td>44.607496</td>\n",
       "      <td>10.949800</td>\n",
       "      <td>5.019456</td>\n",
       "      <td>6.459340</td>\n",
       "      <td>4.461460</td>\n",
       "      <td>3.718469</td>\n",
       "      <td>4.304718</td>\n",
       "      <td>4.069478</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>-391.547699</td>\n",
       "      <td>61.473328</td>\n",
       "      <td>34.779984</td>\n",
       "      <td>42.554768</td>\n",
       "      <td>-2.182075</td>\n",
       "      <td>8.699821</td>\n",
       "      <td>-1.409615</td>\n",
       "      <td>-11.303340</td>\n",
       "      <td>0.550166</td>\n",
       "      <td>-4.555710</td>\n",
       "      <td>...</td>\n",
       "      <td>19.516767</td>\n",
       "      <td>46.948069</td>\n",
       "      <td>5.446670</td>\n",
       "      <td>8.392481</td>\n",
       "      <td>8.957269</td>\n",
       "      <td>5.791789</td>\n",
       "      <td>4.948725</td>\n",
       "      <td>4.011643</td>\n",
       "      <td>5.042315</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>-404.340485</td>\n",
       "      <td>76.251541</td>\n",
       "      <td>25.959827</td>\n",
       "      <td>39.575932</td>\n",
       "      <td>0.379420</td>\n",
       "      <td>-0.940992</td>\n",
       "      <td>-6.228340</td>\n",
       "      <td>-14.371888</td>\n",
       "      <td>1.734153</td>\n",
       "      <td>-11.790402</td>\n",
       "      <td>...</td>\n",
       "      <td>20.260181</td>\n",
       "      <td>47.407920</td>\n",
       "      <td>7.983101</td>\n",
       "      <td>7.196562</td>\n",
       "      <td>7.234455</td>\n",
       "      <td>5.722532</td>\n",
       "      <td>4.125881</td>\n",
       "      <td>3.680128</td>\n",
       "      <td>4.202790</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>-370.484589</td>\n",
       "      <td>65.668503</td>\n",
       "      <td>38.364941</td>\n",
       "      <td>41.208469</td>\n",
       "      <td>-4.550176</td>\n",
       "      <td>4.382659</td>\n",
       "      <td>-0.712863</td>\n",
       "      <td>-9.426854</td>\n",
       "      <td>2.177757</td>\n",
       "      <td>-7.615240</td>\n",
       "      <td>...</td>\n",
       "      <td>20.655909</td>\n",
       "      <td>47.932425</td>\n",
       "      <td>7.639609</td>\n",
       "      <td>7.988176</td>\n",
       "      <td>9.272413</td>\n",
       "      <td>6.288133</td>\n",
       "      <td>4.862371</td>\n",
       "      <td>3.617182</td>\n",
       "      <td>3.027488</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>-423.077972</td>\n",
       "      <td>69.036842</td>\n",
       "      <td>29.720037</td>\n",
       "      <td>37.226368</td>\n",
       "      <td>-3.204175</td>\n",
       "      <td>13.681798</td>\n",
       "      <td>-3.380287</td>\n",
       "      <td>-12.161002</td>\n",
       "      <td>-0.653987</td>\n",
       "      <td>-4.454652</td>\n",
       "      <td>...</td>\n",
       "      <td>19.170236</td>\n",
       "      <td>46.332107</td>\n",
       "      <td>7.829129</td>\n",
       "      <td>8.525364</td>\n",
       "      <td>8.347698</td>\n",
       "      <td>5.883293</td>\n",
       "      <td>4.931897</td>\n",
       "      <td>4.054578</td>\n",
       "      <td>5.303289</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>-409.691040</td>\n",
       "      <td>53.418983</td>\n",
       "      <td>32.701664</td>\n",
       "      <td>39.789028</td>\n",
       "      <td>3.053331</td>\n",
       "      <td>6.652601</td>\n",
       "      <td>-2.778558</td>\n",
       "      <td>-10.420267</td>\n",
       "      <td>2.059204</td>\n",
       "      <td>-8.265667</td>\n",
       "      <td>...</td>\n",
       "      <td>19.250991</td>\n",
       "      <td>46.558196</td>\n",
       "      <td>6.463611</td>\n",
       "      <td>8.537711</td>\n",
       "      <td>8.913887</td>\n",
       "      <td>6.158515</td>\n",
       "      <td>4.747238</td>\n",
       "      <td>4.668172</td>\n",
       "      <td>4.418489</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3723 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3         4          5  \\\n",
       "0    -697.792603  54.890041   0.663465  12.435786  7.733952   0.530750   \n",
       "1    -692.855774  55.363895  -1.548319  16.038305  8.818810  -0.146586   \n",
       "2    -691.587891  58.024662   0.159465  13.624650  5.374113   1.162337   \n",
       "3    -685.105469  55.879421   2.783262  13.252023  6.989670   2.981274   \n",
       "4    -727.104370  62.355034   3.121181  15.064669  8.132434   1.927084   \n",
       "...          ...        ...        ...        ...       ...        ...   \n",
       "3718 -391.547699  61.473328  34.779984  42.554768 -2.182075   8.699821   \n",
       "3719 -404.340485  76.251541  25.959827  39.575932  0.379420  -0.940992   \n",
       "3720 -370.484589  65.668503  38.364941  41.208469 -4.550176   4.382659   \n",
       "3721 -423.077972  69.036842  29.720037  37.226368 -3.204175  13.681798   \n",
       "3722 -409.691040  53.418983  32.701664  39.789028  3.053331   6.652601   \n",
       "\n",
       "             6          7          8          9  ...         59         60  \\\n",
       "0    -3.216631  -3.159394 -10.977551  -2.848711  ...  16.763104  45.346246   \n",
       "1    -1.373392  -5.293180 -11.623182  -1.348284  ...  16.843068  44.918227   \n",
       "2    -2.083360  -5.382585 -10.332824  -3.662081  ...  16.694574  45.031481   \n",
       "3    -1.586029  -6.961661 -10.348489  -3.270769  ...  16.067050  44.119110   \n",
       "4    -3.274656  -3.761792  -9.750299  -4.853837  ...  16.215825  44.607496   \n",
       "...        ...        ...        ...        ...  ...        ...        ...   \n",
       "3718 -1.409615 -11.303340   0.550166  -4.555710  ...  19.516767  46.948069   \n",
       "3719 -6.228340 -14.371888   1.734153 -11.790402  ...  20.260181  47.407920   \n",
       "3720 -0.712863  -9.426854   2.177757  -7.615240  ...  20.655909  47.932425   \n",
       "3721 -3.380287 -12.161002  -0.653987  -4.454652  ...  19.170236  46.332107   \n",
       "3722 -2.778558 -10.420267   2.059204  -8.265667  ...  19.250991  46.558196   \n",
       "\n",
       "             61        62        63        64        65        66        67  \\\n",
       "0     10.712655  4.592027  5.519944  3.719688  3.160476  4.936189  4.376869   \n",
       "1     10.221810  4.672584  5.678050  4.050266  3.132121  4.980014  4.449650   \n",
       "2     10.610992  5.361405  6.009305  3.831685  2.924071  4.630189  4.303702   \n",
       "3      9.945630  4.248116  4.827358  3.778959  2.933074  3.786002  4.105325   \n",
       "4     10.949800  5.019456  6.459340  4.461460  3.718469  4.304718  4.069478   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "3718   5.446670  8.392481  8.957269  5.791789  4.948725  4.011643  5.042315   \n",
       "3719   7.983101  7.196562  7.234455  5.722532  4.125881  3.680128  4.202790   \n",
       "3720   7.639609  7.988176  9.272413  6.288133  4.862371  3.617182  3.027488   \n",
       "3721   7.829129  8.525364  8.347698  5.883293  4.931897  4.054578  5.303289   \n",
       "3722   6.463611  8.537711  8.913887  6.158515  4.747238  4.668172  4.418489   \n",
       "\n",
       "       labels  \n",
       "0     neutral  \n",
       "1     neutral  \n",
       "2     neutral  \n",
       "3     neutral  \n",
       "4        calm  \n",
       "...       ...  \n",
       "3718      sad  \n",
       "3719      sad  \n",
       "3720      sad  \n",
       "3721      sad  \n",
       "3722      sad  \n",
       "\n",
       "[3723 rows x 69 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "05996aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:46:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       396\n",
      "           1       0.74      0.99      0.84       396\n",
      "           2       0.94      0.76      0.84       396\n",
      "           3       0.99      1.00      0.99       396\n",
      "           4       0.80      0.96      0.87       396\n",
      "           5       0.94      0.75      0.83       396\n",
      "           6       0.99      0.87      0.93       396\n",
      "           7       0.90      0.95      0.93       396\n",
      "           8       1.00      0.78      0.87       396\n",
      "           9       0.76      0.97      0.85       396\n",
      "\n",
      "    accuracy                           0.89      3960\n",
      "   macro avg       0.91      0.89      0.89      3960\n",
      "weighted avg       0.91      0.89      0.89      3960\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90       130\n",
      "           1       0.42      0.97      0.59        32\n",
      "           2       0.87      0.72      0.78       130\n",
      "           3       0.99      0.98      0.98       100\n",
      "           4       0.39      0.70      0.50        30\n",
      "           5       0.90      0.70      0.79       132\n",
      "           6       1.00      0.88      0.94       116\n",
      "           7       0.87      0.85      0.86       100\n",
      "           8       0.98      0.79      0.87       131\n",
      "           9       0.31      0.83      0.45        30\n",
      "\n",
      "    accuracy                           0.82       931\n",
      "   macro avg       0.77      0.82      0.77       931\n",
      "weighted avg       0.89      0.82      0.84       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# === Create DataFrame ===\n",
    "features, labels = zip(*data)\n",
    "df = pd.DataFrame(features)\n",
    "df['labels'] = labels\n",
    "\n",
    "# === Encode Labels ===\n",
    "le = LabelEncoder()\n",
    "df['labels'] = le.fit_transform(df['labels'])\n",
    "\n",
    "X = df.drop(columns='labels')\n",
    "y = df['labels']\n",
    "\n",
    "# === Train-test split (with stratification) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Power Transform ===\n",
    "pt = PowerTransformer()\n",
    "X_train = pt.fit_transform(X_train)\n",
    "X_test = pt.transform(X_test)\n",
    "\n",
    "# === Standard Scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === SMOTE for Balanced Sampling ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# === PCA (after resampling) ===\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# === Class Weight Calculation ===\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_resampled)\n",
    "\n",
    "# === XGBoost Model with Regularization ===\n",
    "model = XGBClassifier(\n",
    "    n_estimators=250,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=2.0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === Train Model ===\n",
    "model.fit(X_train_pca, y_train_resampled, sample_weight=sample_weights)\n",
    "\n",
    "# === Evaluate ===\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train_pred = model.predict(X_train_pca)\n",
    "y_test_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Train Classification Report:\")\n",
    "print(classification_report(y_train_resampled, y_train_pred))\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "188e19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Training ===\n",
    "#rf=RandomForestClassifier(max_depth=7,n_estimators=200,random_state=42,class_weight=\"balanced\")\n",
    "#sv= SVC(kernel=\"linear\", C=1, gamma=0.02,class_weight=\"balanced\")\n",
    "#rfecv_model=RFECV(estimator=rf,step=1,cv=5,scoring=\"accuracy\",importance_getter=\"auto\")\n",
    "#rfecv_model.fit(X_train,y_train)\n",
    "#y_pred=rfecv_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dea66734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Classification Report:\\n\", classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8070c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sv= SVC(kernel=\"linear\", C=1, gamma=0.02,class_weight=\"balanced\")\n",
    "#sv.fit(X_train,y_train)\n",
    "#y_pred=sv.predict(X_test)\n",
    "#classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "96e44764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# === Save Model and Preprocessors ===\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(\"pt.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pt, f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "with open(\"pca.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)  # âœ… Save the PCA object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "05a70ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ§ Predicted Emotion: calm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import librosa\n",
    "\n",
    "# === Load model and preprocessors ===\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(\"pt.pkl\", \"rb\") as f:\n",
    "    pt = pickle.load(f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "with open(\"pca.pkl\", \"rb\") as f:\n",
    "    pca = pickle.load(f)  # âœ… Load PCA transformer\n",
    "\n",
    "# === Feature extractor (same structure as training) ===\n",
    "def extract_features_for_test(file):\n",
    "    y, sr = librosa.load(file, sr=22050, mono=True)\n",
    "    features = []\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    features.extend(np.mean(mfccs, axis=1))\n",
    "    features.extend(np.std(mfccs, axis=1))\n",
    "\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "    features.extend(np.std(chroma, axis=1))\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "    features.append(np.std(zcr))\n",
    "\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features.append(np.mean(rms))\n",
    "    features.append(np.std(rms))\n",
    "\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    features.extend(np.mean(contrast, axis=1))\n",
    "    features.extend(np.std(contrast, axis=1))\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# === Path to your audio file ===\n",
    "file_path = r\"C:\\Users\\abdul\\Downloads\\audio-testing\\sad.wav\"\n",
    "\n",
    "# === Extract and preprocess ===\n",
    "features = extract_features_for_test(file_path)\n",
    "X = features.reshape(1, -1)\n",
    "X = pt.transform(X)\n",
    "X = scaler.transform(X)\n",
    "X = pca.transform(X)  # âœ… Apply PCA to match model input shape\n",
    "\n",
    "# === Predict Emotion ===\n",
    "pred = model.predict(X)\n",
    "emotion = le.inverse_transform([pred[0]])[0]\n",
    "\n",
    "print(\"ðŸŽ§ Predicted Emotion:\", emotion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
